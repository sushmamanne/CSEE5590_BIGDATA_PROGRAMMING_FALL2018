# Source
myAgent.sources = apache_server

myAgent.sources.apache_server.type = exec
myAgent.sources.apache_server.command = tail -f /Users/sai/Documents/GitHub/Big_Data_Project_Fall_2018/logs/logs.txt
myAgent.sources.apache_server.batchSize = 1000
myAgent.sources.apache_server.channels = myMemoryChannel

#Memory

# http://flume.apache.org/FlumeUserGuide.html#memory-channel

myAgent.channels = myMemoryChannel

myAgent.channels.myMemoryChannel.type = memory

myAgent.channels.myMemoryChannel.capacity = 200000

myAgent.channels.myMemoryChannel.transactionCapacity = 200000



## Send to sink that spark streaming pulls on

myAgent.sinks = spark1

myAgent.sinks.spark1.type = org.apache.spark.streaming.flume.sink.SparkSink

myAgent.sinks.spark1.hostname = localhost

myAgent.sinks.spark1.port = 33333

myAgent.sinks.spark1.channel = myMemoryChannel
